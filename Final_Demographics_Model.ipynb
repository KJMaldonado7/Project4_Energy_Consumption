{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "089ba5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from scipy.stats import randint\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sqlalchemy import create_engine\n",
    "from urllib.parse import quote_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90fe74ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'psycopg2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# SQLAlchemy connectable\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# DEFAULT engine = create_engine(\"postgresql://USERNAME:%s@HOST/mydatabase\" % quote_plus(\"Password\"))\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpostgresql://postgres:\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m@localhost/Energy_Output_Expenses\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mquote_plus\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpostgres\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m engine\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Read in SQL table\u001b[39;00m\n",
      "File \u001b[0;32m<string>:2\u001b[0m, in \u001b[0;36mcreate_engine\u001b[0;34m(url, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/dev/lib/python3.10/site-packages/sqlalchemy/util/deprecations.py:309\u001b[0m, in \u001b[0;36mdeprecated_params.<locals>.decorate.<locals>.warned\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    303\u001b[0m         _warn_with_version(\n\u001b[1;32m    304\u001b[0m             messages[m],\n\u001b[1;32m    305\u001b[0m             versions[m],\n\u001b[1;32m    306\u001b[0m             version_warnings[m],\n\u001b[1;32m    307\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m    308\u001b[0m         )\n\u001b[0;32m--> 309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dev/lib/python3.10/site-packages/sqlalchemy/engine/create.py:560\u001b[0m, in \u001b[0;36mcreate_engine\u001b[0;34m(url, **kwargs)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    559\u001b[0m             dbapi_args[k] \u001b[38;5;241m=\u001b[39m pop_kwarg(k)\n\u001b[0;32m--> 560\u001b[0m     dbapi \u001b[38;5;241m=\u001b[39m \u001b[43mdialect_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdbapi\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdbapi_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    562\u001b[0m dialect_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdbapi\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m dbapi\n\u001b[1;32m    564\u001b[0m dialect_args\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompiler_linting\u001b[39m\u001b[38;5;124m\"\u001b[39m, compiler\u001b[38;5;241m.\u001b[39mNO_LINTING)\n",
      "File \u001b[0;32m~/anaconda3/envs/dev/lib/python3.10/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py:782\u001b[0m, in \u001b[0;36mPGDialect_psycopg2.dbapi\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdbapi\u001b[39m(\u001b[38;5;28mcls\u001b[39m):\n\u001b[0;32m--> 782\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpsycopg2\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m psycopg2\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'psycopg2'"
     ]
    }
   ],
   "source": [
    "# SQLAlchemy connectable\n",
    "# DEFAULT engine = create_engine(\"postgresql://USERNAME:%s@HOST/mydatabase\" % quote_plus(\"Password\"))\n",
    "engine = create_engine(\"postgresql://postgres:%s@localhost/Energy_Output_Expenses\" % quote_plus(\"postgres\"))\n",
    "engine.connect()\n",
    "\n",
    "# Read in SQL table\n",
    "data = pd.read_sql_table('demographics',engine)\n",
    "\n",
    "# Previous binning technique that did not work as intended\n",
    "# labels = [1, 2, 3, 4, 5]\n",
    "#data['TOTALBTU'] = pd.qcut(data['TOTALBTU'], 5, labels=labels)\n",
    "#data['TOTALDOL'] = pd.qcut(data['TOTALDOL'], 5, labels=labels)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dfe0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any rows with missing values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Drop the 'DOEID' column and update the DataFrame\n",
    "data.drop('DOEID', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdefa68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First attempt\n",
    "# Target and feature variables\n",
    "y = data['TOTALBTU']\n",
    "X = data[['HHSEX', 'HHAGE', 'EMPLOYHH', 'EDUCATION', 'SDESCENT', 'HOUSEHOLDER_RACE', 'NHSLDMEM', 'NUMCHILD', 'MONEYPY']]  # Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d47ac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d06f7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Linear Regression model and train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1546ddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96529a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d552c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate r2 score\n",
    "r2 = r2_score(y_test, predictions)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc5ac9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt 2\n",
    "# Define target vector\n",
    "y = data['TOTALBTU']\n",
    "X = data[['HHSEX', 'HHAGE', 'EMPLOYHH', 'EDUCATION', 'SDESCENT', 'HOUSEHOLDER_RACE', 'NHSLDMEM', 'NUMCHILD', 'MONEYPY']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86239aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as skl\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)\n",
    "\n",
    "# Create scaler instance\n",
    "X_scaler = skl.preprocessing.StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e547106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Keras Sequential model and add more than one Dense hidden layer\n",
    "import tensorflow as tf\n",
    "\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "nn_model.add(tf.keras.layers.Dense(units=6, activation=\"relu\", input_dim=2))\n",
    "\n",
    "nn_model.add(tf.keras.layers.Dense(units=6, activation=\"relu\"))\n",
    "\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the Sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66148724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and train over more than 100 epochs\n",
    "# nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# fit_model = nn_model.fit(X_train_scaled, y_train, epochs=10)\n",
    "\n",
    "# ERROR:\n",
    "# ValueError: Exception encountered when calling Sequential.call().\n",
    "\n",
    "# Input 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (None, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6760394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt 3 (SUCCESSFUL)\n",
    "\n",
    "# Define a function to perform binning on TOTALBTU column\n",
    "def bin_total_btu(total_btu):\n",
    "    if total_btu < 50000:\n",
    "        return 'Low'\n",
    "    elif total_btu >= 50000 and total_btu < 100000:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'High'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d751e627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply binning function to create a new column 'BTU_Bin'\n",
    "data['BTU_Bin'] = data['TOTALBTU'].apply(bin_total_btu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3efa272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one-hot encoding on the 'BTU_Bin' column\n",
    "X_encoded = pd.get_dummies(data.drop(['TOTALBTU'], axis=1), columns=['BTU_Bin'], drop_first=True)\n",
    "y = data['TOTALBTU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03abecd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=.1, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8613c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dd397b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Linear Regression model\n",
    "lr_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024baefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "lr_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94335c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = lr_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c1fd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R-squared (R2): {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cdb790",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
